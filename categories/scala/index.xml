<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Scala on Ross Lawley</title>
    <link>http://rosslawley.co.uk/categories/scala/</link>
    <description>Recent content in Scala on Ross Lawley</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-gb</language>
    <lastBuildDate>Mon, 27 Jun 2016 22:10:30 +0100</lastBuildDate>
    <atom:link href="http://rosslawley.co.uk/categories/scala/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>MongoDB Scala Connector Released</title>
      <link>http://rosslawley.co.uk/mongodb-spark-connector-released/</link>
      <pubDate>Mon, 27 Jun 2016 22:10:30 +0100</pubDate>
      
      <guid>http://rosslawley.co.uk/mongodb-spark-connector-released/</guid>
      <description>

&lt;p&gt;&lt;img style=&#34;max-width: 100%;&#34; src=&#34;http://rosslawley.co.uk/images/sparks.jpg&#34;&gt;&lt;/p&gt;

&lt;p&gt;The new MongoDB Spark connector has been released!&lt;/p&gt;

&lt;p&gt;Last month I &lt;a href=&#34;http://rosslawley.co.uk/introducing-a-new=mongodb-spark-connector/&#34;&gt;announced&lt;/a&gt;
 that the new Spark connector for &lt;a href=&#34;http://mongodb.org&#34;&gt;MongoDB&lt;/a&gt; was in beta. After some invaluable
 testing by the community, I&amp;rsquo;m excited to announce that the first official release is now available from
 &lt;a href=&#34;https://spark-packages.org/package/mongodb/mongo-spark&#34;&gt;spark-packages&lt;/a&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;&amp;gt; $SPARK_HOME/bin/spark-shell --packages org.mongodb.spark:mongo-spark-connector_2.10:1.0.0
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;a-clean-simple-connector:8a624a4e7030bfeca46590a8e6ef01b3&#34;&gt;A clean, simple connector.&lt;/h2&gt;

&lt;p&gt;At &lt;a href=&#34;http://mongodb.org/&#34;&gt;MongoDB&lt;/a&gt; we&amp;rsquo;ve been listening to your feedback about what you would like from a new mongodb connector.
With that in mind we&amp;rsquo;ve written a totally new idiomatic connector for spark:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;import com.mongodb.spark._
import com.mongodb.spark.sql._

// Loading data is simple:
val rdd = sc.loadFromMongoDB()     // Uses the SparkConf for configuration
println(rdd.count)
println(rdd.first.toJson)

// DataFrames and DataSets made simple:
// Infers the schema (samples the collection)
val df = sqlContext.loadFromMongoDB().toDF()
df.filter(df(&amp;quot;age&amp;quot;) &amp;lt; 100).show()  // Passes filter to MongoDB

// Schema provided via a Case Class
val dataframeExplicit = sqlContext.loadFromMongoDB().toDF[Character]()
val dataSet = sqlContext.loadFromMongoDB().toDS[Character]()

// Writing data to MongoDB is also easy:
val centenarians = sqlContext.sql(&amp;quot;SELECT name, age FROM characters WHERE age &amp;gt;= 100&amp;quot;)
centenarians.write.option(&amp;quot;collection&amp;quot;, &amp;quot;hundredClub&amp;quot;).mongo()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;More examples and full documentation can be found on the &lt;a href=&#34;https://docs.mongodb.com/spark-connector/&#34;&gt;documentation&lt;/a&gt; site.&lt;/p&gt;

&lt;h2 id=&#34;feedback-wanted:8a624a4e7030bfeca46590a8e6ef01b3&#34;&gt;Feedback wanted&lt;/h2&gt;

&lt;p&gt;We would love to have your feedback on the new driver, so please feel free to post to the &lt;a href=&#34;https://groups.google.com/forum/#!forum/mongodb-user&#34;&gt;MongoDB User&lt;/a&gt; mailing list or
add feature requests to the &lt;a href=&#34;https://jira.mongodb.org/browse/SPARK/&#34;&gt;Jira project&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Enjoy!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>MongoDB Scala Connector releases!</title>
      <link>http://rosslawley.co.uk/mongodb-spark-connector-1.1.0/</link>
      <pubDate>Mon, 27 Jun 2016 22:10:30 +0100</pubDate>
      
      <guid>http://rosslawley.co.uk/mongodb-spark-connector-1.1.0/</guid>
      <description>

&lt;p&gt;Version 1.1.0 of the &lt;a href=&#34;https://docs.mongodb.com/spark-connector/&#34;&gt;MongoDB Spark connector&lt;/a&gt; has been released. As well as the
MongoDB Spark Connector 2.0.0-rc0, bring Spark 2.0 support.&lt;/p&gt;

&lt;h2 id=&#34;1-1-0:989f2bc3ab8dd607253fcfdcaa7b362d&#34;&gt;1.1.0&lt;/h2&gt;

&lt;p&gt;This is the first release after the 1.0.0 driver and contains some API improvements and updates based on feedback from users.
Many thanks to all those that have provided feedback either through the MongoDB User &lt;a href=&#34;https://groups.google.com/forum/#!forum/mongodb-user&#34;&gt;mailing list&lt;/a&gt;,
via  &lt;a href=&#34;stackoverflow.com/questions/tagged/apache-spark+mongodb&#34;&gt;StackOverflow&lt;/a&gt; or via the &lt;a href=&#34;https://jira.mongodb.org/browse/SPARK/&#34;&gt;Spark Jira project&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s been thrilling to get such great feedback and find out about some of the real world scenarios the connector has been used for. One of my
favourites so far has been about how &lt;a href=&#34;https://www.mongodb.com/blog/post/mongodb-and-apache-spark-at-china-eastern-airlines&#34;&gt;China Eastern Airlines&lt;/a&gt; and how they
use the connector to save time and money.  But wether you&amp;rsquo;re a big or small user of the connector, I&amp;rsquo;d really appreciate your feedback and comments. It really is central to making this connector
even better and more accessible.&lt;/p&gt;

&lt;h3 id=&#34;improvements-in-1-1-0:989f2bc3ab8dd607253fcfdcaa7b362d&#34;&gt;Improvements in 1.1.0&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Saving DataFrames with an &lt;code&gt;_id&lt;/code&gt; field will updated in place, rather than error.&lt;/li&gt;
&lt;li&gt;You can now use SQL to &lt;code&gt;INSERT INTO&lt;/code&gt; a collection.&lt;/li&gt;
&lt;li&gt;Added support for Spark MapTypes in schemas.&lt;/li&gt;
&lt;li&gt;IsNotNull filter improved so that it also checks the field exists&lt;/li&gt;
&lt;li&gt;Added helpers for defining the schemas and querying unsupported MongoDB datatypes.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;See the full &lt;a href=&#34;https://github.com/mongodb/mongo-spark/blob/1.x/doc/7-Changelog.md&#34;&gt;changelog&lt;/a&gt; for detailed information and links to the Jira tickets.&lt;/p&gt;

&lt;p&gt;The new&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;&amp;gt; $SPARK_HOME/bin/spark-shell --packages org.mongodb.spark:mongo-spark-connector_2.10:1.1.0
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;spark-2-0-support:989f2bc3ab8dd607253fcfdcaa7b362d&#34;&gt;Spark 2.0 support&lt;/h2&gt;

&lt;p&gt;The 2.0.0.rc-0 connector is available from &lt;a href=&#34;http://search.maven.org/#search%7Cga%7C1%7Cg%3A%22org.mongodb.spark%22&#34;&gt;maven central&lt;/a&gt; and provides support for Spark 2.0, as well as
all the improvements from the 1.1.0 generation of the driver.&lt;/p&gt;

&lt;p&gt;There were a few minor API changes required to support Spark 2.0:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;DataFrame and Dataset are now unified.
In Scala and Java, DataFrame and Dataset have been unified, i.e. DataFrame is just a type alias for Dataset of Row.&lt;/li&gt;
&lt;li&gt;SparkSession
The new entry point that replaces the old SQLContext and HiveContext for DataFrame and Dataset APIs.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The actual code changes to interact with MongoDB should be minimal and are designed to be as unobtrusive as possible.&lt;/p&gt;

&lt;h2 id=&#34;feedback-wanted:989f2bc3ab8dd607253fcfdcaa7b362d&#34;&gt;Feedback wanted&lt;/h2&gt;

&lt;p&gt;We would love to have your feedback on the connector, so please feel free to post to the &lt;a href=&#34;https://groups.google.com/forum/#!forum/mongodb-user&#34;&gt;MongoDB User&lt;/a&gt; mailing list or
add feature requests to the &lt;a href=&#34;https://jira.mongodb.org/browse/SPARK/&#34;&gt;Jira project&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Enjoy!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Introducing a new MongoDB Spark Connector</title>
      <link>http://rosslawley.co.uk/introducing-a-new=mongodb-spark-connector/</link>
      <pubDate>Wed, 18 May 2016 13:43:25 +0100</pubDate>
      
      <guid>http://rosslawley.co.uk/introducing-a-new=mongodb-spark-connector/</guid>
      <description>

&lt;h2 id=&#34;update:b4450e2a5da78ad49e7021b6ad22ca92&#34;&gt;Update!&lt;/h2&gt;

&lt;p&gt;The MongoDB Spark connector has been &lt;a href=&#34;http://rosslawley.co.uk/mongodb-spark-connector-released/&#34;&gt;released&lt;/a&gt;! See the official
&lt;a href=&#34;https://docs.mongodb.com/spark-connector/&#34;&gt;documentation&lt;/a&gt; for more information on getting started!&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Following on from the &lt;a href=&#34;https://www.mongodb.com/blog/post/mongodb-connector-for-apache-spark-announcing-early-access-program-and-new-spark-training&#34;&gt;official announcement&lt;/a&gt; yesterday, I&amp;rsquo;m really excited to write a few words about new &lt;strong&gt;MongoDB Spark Connector&lt;/strong&gt;.&lt;/p&gt;

&lt;h2 id=&#34;getting-started:b4450e2a5da78ad49e7021b6ad22ca92&#34;&gt;Getting started&lt;/h2&gt;

&lt;p&gt;Before I go into detail about the hows and whys, first have a look at a quick usage example:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;import com.mongodb.spark._
import com.mongodb.spark.sql._

// Loading data is simple:
val rdd = sc.loadFromMongoDB()     // Uses the SparkConf for configuration
println(rdd.count)
println(rdd.first.toJson)

// DataFrames and DataSets made simple:
// Infers the schema (samples the collection)
val df = sqlContext.loadFromMongoDB().toDF()
df.filter(df(&amp;quot;age&amp;quot;) &amp;lt; 100).show()  // Passes filter to MongoDB

// Schema provided via a Case Class
val dataframeExplicit = sqlContext.loadFromMongoDB().toDF[Character]()
val dataSet = sqlContext.loadFromMongoDB().toDS[Character]()

// Writing data to MongoDB is also easy:
val centenarians = sqlContext.sql(&amp;quot;SELECT name, age FROM characters WHERE age &amp;gt;= 100&amp;quot;)
centenarians.write.option(&amp;quot;collection&amp;quot;, &amp;quot;hundredClub&amp;quot;).mongo()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The MongoDB Spark Connector supports Spark 1.6.1 and Scala 2.10 or 2.11. You can download it from Sonatype with these coordinates:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;&amp;quot;org.mongodb.spark&amp;quot; %% &amp;quot;mongo-spark-connector&amp;quot; % &amp;quot;0.2&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;backstory:b4450e2a5da78ad49e7021b6ad22ca92&#34;&gt;Backstory&lt;/h2&gt;

&lt;p&gt;Since January writing a new shiny Spark Connector designed from the ground up. Having initially played with Spark during one of our Skunkworks days over a year ago, I knew we could make a great connector to combine these two wonderful technologies. Last summer we welcomed Marko Vojvodic to the JVM team and during his internship he worked on prototyping a connector in Java. Marko looked at some of the hard problems when writing a great connector; type cohersion, data partitioning and data locality to name a few.&lt;/p&gt;

&lt;p&gt;We have a few JVM projects keeping us busy at &lt;a href=&#34;http://www.mongodb.com&#34;&gt;MongoDB&lt;/a&gt;, but in January I got time to start focusing on building the Spark connector. I started with Scala and ported some of Marko&amp;rsquo;s code, wrote new code and built a new API from the ground up.&lt;/p&gt;

&lt;p&gt;In April we quietly released the first beta version and solicited feedback from a select group of MongoDB power users. Since then a number of kinks have been ironed out resulting in the 0.2 release. Now we&amp;rsquo;re opening up the beta and asking the wider community for feedback, before we release a 1.0 version.&lt;/p&gt;

&lt;h2 id=&#34;why-build-a-new-mongodb-spark-connector:b4450e2a5da78ad49e7021b6ad22ca92&#34;&gt;Why build a new MongoDB Spark Connector?&lt;/h2&gt;

&lt;p&gt;I&amp;rsquo;ve been asked this a few times, after all the Hadoop connector supports Spark. The reason for a native connector is simple; Spark has quickly grown in popularity and use. It&amp;rsquo;s growth reminds me of MongoDBs and naturally users want to combine both products. So it&amp;rsquo;s only logical to create a &lt;em&gt;first class experience&lt;/em&gt; and let these users get the most out of combining both technologies.
I really hope we have gone a long way to achieving that with this new connector.&lt;/p&gt;

&lt;h2 id=&#34;language-support:b4450e2a5da78ad49e7021b6ad22ca92&#34;&gt;Language support&lt;/h2&gt;

&lt;p&gt;The MongoDB Spark Connector supports all the languages Spark supports: Scala, Java, Python and R but under the hood it&amp;rsquo;s written in Scala. This helped keep the API clean because we can make full use of Scala magic like implicits. To keep Java folk happy there&amp;rsquo;s also a special Java API that hides some of the &amp;ldquo;Scala-ness&amp;rdquo; such as strange method names from Java users. Hat-tip to the Databricks &lt;a href=&#34;https://github.com/databricks/scala-style-guide#java-interoperability&#34;&gt;Java interoperability&lt;/a&gt; guide, it&amp;rsquo;s super helpful when considering how to consume a Scala API from Java.&lt;/p&gt;

&lt;h2 id=&#34;feedback-wanted:b4450e2a5da78ad49e7021b6ad22ca92&#34;&gt;Feedback wanted!&lt;/h2&gt;

&lt;p&gt;I hope that has got you interested, I would love to have your feedback on the new connector good or bad. So please feel free to email me directly or post to the &lt;a href=&#34;https://groups.google.com/forum/#!forum/mongodb-user&#34;&gt;MongoDB User&lt;/a&gt; mailing list. If you are currently using an alternative connector for MongoDB and Spark, I&amp;rsquo;d &lt;strong&gt;really interested&lt;/strong&gt; in any feedback.&lt;/p&gt;

&lt;p&gt;The connector is still in Beta, so there maybe changes to the API, but I&amp;rsquo;m hoping it&amp;rsquo;s stable now. If you do encounter any problems or find a bug please report it by opening an issue at &lt;a href=&#34;https://jira.mongodb.org/browse/SPARK&#34;&gt;jira.mongodb.org/browse/SPARK&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The quickest way to get up and running with the new connector is via the &lt;a href=&#34;https://github.com/mongodb/mongo-spark/blob/master/doc/0-introduction.md&#34;&gt;introduction&lt;/a&gt; on github. There is also the &lt;a href=&#34;https://university.mongodb.com/courses/M233/about&#34;&gt;M233: Getting Started with Spark and MongoDB&lt;/a&gt; course over at the MongoDB University.&lt;/p&gt;

&lt;p&gt;Happy Big Data Computing.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>MongoDB Scala Driver Released</title>
      <link>http://rosslawley.co.uk/mongodb-scala-driver-released/</link>
      <pubDate>Tue, 20 Oct 2015 13:10:30 +0100</pubDate>
      
      <guid>http://rosslawley.co.uk/mongodb-scala-driver-released/</guid>
      <description>

&lt;p&gt;&lt;img style=&#34;max-width: 100%;&#34; src=&#34;http://rosslawley.co.uk/images/starNebula.jpg&#34;&gt;&lt;/p&gt;

&lt;p&gt;The new Scala Driver for MongoDB has been released!&lt;/p&gt;

&lt;p&gt;Last month I &lt;a href=&#34;http://rosslawley.co.uk/introducing-mongodb-scala-driver/&#34;&gt;announced&lt;/a&gt;
 the first release candidate of a new idiomatic Scala Driver for &lt;a href=&#34;http://mongodb.org&#34;&gt;MongoDB&lt;/a&gt; and I&amp;rsquo;m excited to announce that the first official release is now available on sonatype for Scala 2.11:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt; &amp;quot;org.mongodb.scala&amp;quot; %% &amp;quot;mongo-scala-driver&amp;quot; % &amp;quot;1.0.0&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;a-clean-simple-scala-driver:0667d62b0610317a357b6826680f4d5a&#34;&gt;A clean, simple Scala driver.&lt;/h2&gt;

&lt;p&gt;At &lt;a href=&#34;http://mongodb.org/&#34;&gt;MongoDB&lt;/a&gt; we&amp;rsquo;ve been listening to your feedback about what you would like from a new Scala driver. With that in mind we&amp;rsquo;ve written a totally new Scala driver.  Here are some of the highlights:&lt;/p&gt;

&lt;p&gt;&lt;img style=&#34;float:right;&#34; src=&#34;http://mongodb.github.io/mongo-scala-driver/s/img/mongoScalaLogo.png&#34;&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;A modern idiomatic Scala driver with asynchronous and non-blocking IO.&lt;/li&gt;
&lt;li&gt;A clean modern API following the latest MongoDB driver &lt;a href=&#34;https://github.com/mongodb/specifications&#34;&gt;specifications&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;A new namespace for Scala &lt;code&gt;org.mongodb.scala&lt;/code&gt;. No more confusion about what classes required for Scala.&lt;/li&gt;
&lt;li&gt;A new &lt;a href=&#34;http://mongodb.github.io/mongo-scala-driver/1.0/reference/observables/&#34;&gt;&lt;code&gt;Observable&lt;/code&gt;&lt;/a&gt; type that is both composable and flexible enough to handle streams of data from MongoDB.&lt;/li&gt;
&lt;li&gt;New immutable and mutable type safe &lt;a href=&#34;http://mongodb.github.io/mongo-scala-driver/1.0/bson/documents/&#34;&gt;&lt;code&gt;Document&lt;/code&gt;&lt;/a&gt; classes with all the convenience of a &lt;code&gt;Map&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Comprehensive &lt;a href=&#34;http://mongodb.github.io/mongo-scala-driver/&#34;&gt;documentation&lt;/a&gt; site to help get you started.&lt;/li&gt;
&lt;li&gt;Easy &lt;a href=&#34;http://mongodb.github.io/mongo-scala-driver/1.0/integrations/&#34;&gt;integration&lt;/a&gt; with other Reactive libraries such as &lt;a href=&#34;http://reactivex.io/rxscala/&#34;&gt;RxScala&lt;/a&gt; and &lt;a href=&#34;http://www.reactive-streams.org/&#34;&gt;Reactive Streams&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Below is a quick example to whet your appetite:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;// Connect to the users collection in mydb
val mongoClient: MongoClient = MongoClient()
val database: MongoDatabase = mongoClient.getDatabase(&amp;quot;mydb&amp;quot;)
val collection: MongoCollection[Document] = database.getCollection(&amp;quot;users&amp;quot;)

// The Document ADT enforces type safety and can implicitly box native scala types to BSON types
val martin = Document(&amp;quot;user&amp;quot; -&amp;gt; &amp;quot;Martin&amp;quot;)  // &amp;quot;Martin&amp;quot; becomes BsonString(&amp;quot;Martin&amp;quot;)

// Alternatively, create Documents from Json
val query = Document(&amp;quot;&amp;quot;&amp;quot;{user: &amp;quot;Martin&amp;quot;}&amp;quot;&amp;quot;&amp;quot;)

// Lets run a query for all Martins and print out the json representation of each document
collection.find(query).subscribe(
  (user: Document) =&amp;gt; println(user.toJson()),                         // onNext
  (error: Throwable) =&amp;gt; println(s&amp;quot;Query failed: ${error.getMessage}&amp;quot;), // onError
  () =&amp;gt; println(&amp;quot;Done&amp;quot;)                                               // onComplete
)

// Want Futures? No problems!
val futureUsers: Future[Seq[Document]] = collection.find(query).toFuture()
val firstMartin: Future[Document] = collection.find(query).first().head()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;More examples and full documentation can be found on the &lt;a href=&#34;http://mongodb.github.io/mongo-scala-driver&#34;&gt;documentation&lt;/a&gt; hub, including a full &lt;a href=&#34;http://mongodb.github.io/mongo-scala-driver/1.0/getting-started/&#34;&gt;getting started&lt;/a&gt; guide.&lt;/p&gt;

&lt;h2 id=&#34;feedback-wanted:0667d62b0610317a357b6826680f4d5a&#34;&gt;Feedback wanted&lt;/h2&gt;

&lt;p&gt;We would love to have your feedback on the new driver, so please feel free to post to the &lt;a href=&#34;https://groups.google.com/forum/#!forum/mongodb-user&#34;&gt;MongoDB User&lt;/a&gt; mailing list or add feature requests to the &lt;a href=&#34;https://jira.mongodb.org/browse/SCALA/&#34;&gt;Jira project&lt;/a&gt;. There are a number of items on the roadmap such as; MongoDB Server 3.2 and Case Class support but all feature requests are welcome.&lt;/p&gt;

&lt;p&gt;Enjoy!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Introducing a new MongoDB Scala Driver</title>
      <link>http://rosslawley.co.uk/introducing-mongodb-scala-driver/</link>
      <pubDate>Wed, 23 Sep 2015 13:00:00 +0100</pubDate>
      
      <guid>http://rosslawley.co.uk/introducing-mongodb-scala-driver/</guid>
      <description>

&lt;h2 id=&#34;update-now-released-hugoshortcode-1:30e1b2e2e4927e03c8ac09809618f25b&#34;&gt;Update - &lt;a href=&#34;http://rosslawley.co.uk/mongodb-scala-driver-released/&#34;&gt;now released!&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;I&amp;rsquo;m really pleased to announce the first release candidate of a new MongoDB Scala Driver!&lt;/p&gt;

&lt;p&gt;&lt;img style=&#34;float:right;&#34; src=&#34;http://mongodb.github.io/mongo-scala-driver/s/img/mongoScalaLogo.png&#34;&gt;&lt;/p&gt;

&lt;h2 id=&#34;insider-information:30e1b2e2e4927e03c8ac09809618f25b&#34;&gt;Insider information&lt;/h2&gt;

&lt;p&gt;At &lt;a href=&#34;http://mongodb.org/&#34;&gt;MongoDB&lt;/a&gt; we&amp;rsquo;ve been really busy, back in April we &lt;a href=&#34;https://www.mongodb.com/blog/post/introducing-30-java-driver&#34;&gt;introduced&lt;/a&gt; the 3.0 Java driver. It was a massive undertaking that included numerous improvements and updates. What got me most excited with the 3.0 release was the introduction of a new fully asynchronous, non-blocking driver. Using this asynchronous driver as a base we also released an &lt;a href=&#34;mongodb.github.io/mongo-java-driver-rx&#34;&gt;RxJava&lt;/a&gt; driver and a &lt;a href=&#34;http://mongodb.github.io/mongo-java-driver-reactivestreams&#34;&gt;Reactive Streams&lt;/a&gt; driver.&lt;/p&gt;

&lt;p&gt;Today we are announcing a new MongoDB Scala Driver, which also builds upon the asynchronous driver, whilst still providing a first class Scala experience.&lt;/p&gt;

&lt;h2 id=&#34;scala-specifics:30e1b2e2e4927e03c8ac09809618f25b&#34;&gt;Scala specifics&lt;/h2&gt;

&lt;p&gt;This new Scala driver required much more than a simple wrapping of the Java driver. Here are some of the highlights:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;A modern idiomatic Scala driver with asynchronous and non-blocking IO.&lt;/li&gt;
&lt;li&gt;A new &lt;a href=&#34;http://mongodb.github.io/mongo-scala-driver/1.0/reference/observables/&#34;&gt;&lt;code&gt;Observable&lt;/code&gt;&lt;/a&gt; type that is both composable and flexible enough to handle streams of data from MongoDB.&lt;/li&gt;
&lt;li&gt;New immutable and mutable type safe &lt;a href=&#34;http://mongodb.github.io/mongo-scala-driver/1.0/bson/documents/&#34;&gt;&lt;code&gt;Document&lt;/code&gt;&lt;/a&gt; classes with all the convenience of a &lt;code&gt;Map&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;A clean modern API following the latest MongoDB driver &lt;a href=&#34;https://github.com/mongodb/specifications&#34;&gt;specifications&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;A new namespace for Scala &lt;code&gt;org.mongodb.scala&lt;/code&gt;. No more confusion about what classes required for the Scala driver.&lt;/li&gt;
&lt;li&gt;Comprehensive &lt;a href=&#34;http://mongodb.github.io/mongo-scala-driver/&#34;&gt;documentation&lt;/a&gt; site to help get you started.&lt;/li&gt;
&lt;li&gt;Easy &lt;a href=&#34;http://mongodb.github.io/mongo-scala-driver/1.0/integrations/&#34;&gt;integration&lt;/a&gt; with other Reactive libraries such as &lt;a href=&#34;http://reactivex.io/rxscala/&#34;&gt;RxScala&lt;/a&gt; and &lt;a href=&#34;http://www.reactive-streams.org/&#34;&gt;Reactive Streams&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Below is a quick example to whet your appetite:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;// Connect to the users collection in mydb
val mongoClient: MongoClient = MongoClient()
val database: MongoDatabase = mongoClient.getDatabase(&amp;quot;mydb&amp;quot;)
val collection: MongoCollection[Document] = database.getCollection(&amp;quot;users&amp;quot;)

// The Document ADT enforces type safety and can implicitly box native scala types to BSON types
val query = Document(&amp;quot;user&amp;quot; -&amp;gt; &amp;quot;Martin&amp;quot;)  // &amp;quot;Martin&amp;quot; becomes BsonString(&amp;quot;Martin&amp;quot;)

// Lets run a query for all Martins and print out the json representation of each document
collection.find(query).subscribe(
  (user: Document) =&amp;gt; println(user.toJson()),                         // onNext
  (error: Throwable) =&amp;gt; println(s&amp;quot;Query failed: ${error.getMessage}&amp;quot;), // onError
  () =&amp;gt; println(&amp;quot;Done&amp;quot;)                                               // onComplete
)

// Want Futures? No problems!
val futureUsers: Future[Seq[Document]] = collection.find(query).toFuture()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Available on sonatype for Scala 2.11:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;&amp;quot;org.mongodb.scala&amp;quot; %% &amp;quot;mongo-scala-driver&amp;quot; % &amp;quot;1.0.0-rc0&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;feedback-wanted:30e1b2e2e4927e03c8ac09809618f25b&#34;&gt;Feedback wanted&lt;/h2&gt;

&lt;p&gt;We would love to have your feedback on the new driver, so please feel free to email me directly or post to the &lt;a href=&#34;https://groups.google.com/forum/#!forum/mongodb-user&#34;&gt;MongoDB User&lt;/a&gt; mailing list.&lt;/p&gt;

&lt;p&gt;The best place to get up and running with the new driver is the &lt;a href=&#34;http://mongodb.github.io/mongo-scala-driver/1.0/getting-started/&#34;&gt;getting started&lt;/a&gt; guide.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How to: Handle multiple Scala versions</title>
      <link>http://rosslawley.co.uk/how-to-handle-multiple-scala-versions/</link>
      <pubDate>Wed, 23 Apr 2014 00:00:00 +0000</pubDate>
      
      <guid>http://rosslawley.co.uk/how-to-handle-multiple-scala-versions/</guid>
      <description>

&lt;p&gt;I recently upgraded &lt;a href=&#34;http://mongodb.github.io/casbah/&#34;&gt;Casbah&lt;/a&gt; to support the latest Scala 2.11 release and for the first time when supporting multiple Scala versions I hit a stumbling block.  If you&amp;rsquo;re writing a library that wants to support multiple versions of Scala in a single code base, it&amp;rsquo;s generally easy isn&amp;rsquo;t it? Thankfully, it is as &lt;a href=&#34;http://www.scala-sbt.org/&#34;&gt;sbt&lt;/a&gt; can do the heavy lifting for you.&lt;/p&gt;

&lt;h2 id=&#34;three-steps-to-success:7a5c4c34d420fcc6185eaa05487dbc11&#34;&gt;Three steps to success&lt;/h2&gt;

&lt;p&gt;The sbt documentation covers the basics nicely in their &lt;a href=&#34;http://www.scala-sbt.org/release/docs/Detailed-Topics/Cross-Build.html&#34;&gt;cross build&lt;/a&gt; documentation.  But what&amp;rsquo;s the path to success?&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Choose the Scala&amp;rsquo;s you are going to support.&lt;/p&gt;

&lt;p&gt;Set the &lt;code&gt;crossScalaVersions&lt;/code&gt; setting in your build file to define the Scala versions you want to support. In Casbah we support: &lt;code&gt;crossScalaVersions := Seq(&amp;quot;2.11.0&amp;quot;, &amp;quot;2.10.4&amp;quot;, &amp;quot;2.9.3&amp;quot;)&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Configure libraries&lt;/p&gt;

&lt;p&gt;Here it can get hairy because third party libraries may not support all your favoured scala builds in their latest release.  If they do, then happy days but if not you may have to pick out each library version as needed.  Here is an example from the Casbah build:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// In the build settings append to the library dependencies
libraryDependencies &amp;lt;++= scalaVersion (sv =&amp;gt; Seq(specs2(sv), scalatime(sv)))


// Helper method to pattern match against the scala version and return the correct specs version
def specs2(scalaVersion: String) =
  (scalaVersion match {
    case &amp;quot;2.9.3&amp;quot;   =&amp;gt; &amp;quot;org.specs2&amp;quot; %% &amp;quot;specs2&amp;quot; % &amp;quot;1.12.4.1&amp;quot;
    case _ =&amp;gt; &amp;quot;org.specs2&amp;quot; %% &amp;quot;specs2&amp;quot; % &amp;quot;2.3.11&amp;quot;
  }) % &amp;quot;test&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As the latest Specs build &lt;code&gt;2.3.11&lt;/code&gt; doesn&amp;rsquo;t support Scala 2.9.3 we have to use the older &lt;code&gt;1.12.4.1&lt;/code&gt; version for 2.9.3.  The downside is we can&amp;rsquo;t yet use some of the nicer newer features of the Specs library in our test suite.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Scala version specific code.&lt;/p&gt;

&lt;p&gt;This is the real challenge, what do you do if you need specific code for a specific version of Scala?  Hopefully, you&amp;rsquo;ll never need to but this isn&amp;rsquo;t always the case as I found with Casbah.  We use &lt;code&gt;BeanInfo&lt;/code&gt; annotation and it lives in &lt;code&gt;scala.reflection&lt;/code&gt; in Scala 2.9.3 and in &lt;code&gt;scala.beans&lt;/code&gt; in 2.11.&lt;/p&gt;

&lt;p&gt;So how can we get round this? Luckily, Scala 2.10 gave me a hint as &lt;code&gt;BeanInfo&lt;/code&gt; had been depreciated in &lt;code&gt;scala.reflection&lt;/code&gt; but they had mirrored it in a &lt;a href=&#34;https://github.com/scala/scala/blob/v2.10.4/src/library/scala/reflect/package.scala#L55-L56&#34;&gt;package object&lt;/a&gt;. I could use the same trick in Casbah! However, I would need a version for Scala 2.9.3 to point to &lt;code&gt;scala.reflect.BeanInfo&lt;/code&gt; and a version for 2.10 &amp;amp; 2.11. Then update all the code to point to the scala specific package object.&lt;/p&gt;

&lt;p&gt;As the code would be version specific it couldn&amp;rsquo;t live in the &lt;code&gt;src/main/scala&lt;/code&gt; directory as it wouldn&amp;rsquo;t compile. So instead I created specific Scala directories in &lt;code&gt;src/main&lt;/code&gt; like so:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;./scala
./scala_2.9.3  // Scala 2.9.3 specific code
./scala_2.10   // Scala 2.10 specific code
./scala_2.11   // Scala 2.11 specific code
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As Scala 2.10 &amp;amp; 2.11 point versions will be binary compatible I only need a top level directory for them.  Then alls that&amp;rsquo;s needed is to add these source directories to the build:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;unmanagedSourceDirectories in Compile &amp;lt;+= (sourceDirectory in Compile, scalaBinaryVersion){
  (s, v) =&amp;gt; s / (&amp;quot;scala_&amp;quot;+v)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This adds extra source directories to the compile step and using &lt;code&gt;scalaBinaryVersion&lt;/code&gt; I get the binary compatible versions (so it&amp;rsquo;s 2.11 for all 2.11 releases but would be 2.9.3, 2.9.2, 2.9.1 for the non compatible point releases from the 2.9 series).&lt;/p&gt;

&lt;p&gt;The fix in Casbah was to simply add a &lt;code&gt;beans.scala&lt;/code&gt; for the scala specific versions and create a &lt;code&gt;BeanInfo&lt;/code&gt; type which points to the correct scala package. Problem solved.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Sbt allow you to run any command against multiple versions of Scala. &lt;code&gt;./sbt +test&lt;/code&gt; will test against all your &lt;code&gt;crossScalaVersions&lt;/code&gt; of Scala and hopefully confirm the code works as expected.  If I want to test a specific version use a double plus sign and add the version string to the arguments eg: &lt;code&gt;./sbt ++ 2.9.3 test&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&#34;final-thoughts:7a5c4c34d420fcc6185eaa05487dbc11&#34;&gt;Final thoughts&lt;/h2&gt;

&lt;p&gt;Scala is a relatively fast moving ecosystem with new major releases every 13 months or so.  When I took over Casbah it supported 6 binary incompatible versions of Scala! From 2.8.1 to 2.9.3. Happily, Scala patch versions from 2.10.0 on have become binary compatible making supporting multiple versions of Scala easier.  However, one of the key issues for maintaining a library is to know when to end of life an old Scala version, so to keep the library fresh.&lt;/p&gt;

&lt;p&gt;In Casbah supporting the current and last major versions of Scala gives users support for the latest MongoDB version and allows them some flexibility when it comes to updating Scala. Generally, this has been a trouble free process and as shown above problems are solvable in just three easy steps.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>RxJava - understandably reactive</title>
      <link>http://rosslawley.co.uk/rx-java/</link>
      <pubDate>Wed, 06 Nov 2013 00:00:00 +0000</pubDate>
      
      <guid>http://rosslawley.co.uk/rx-java/</guid>
      <description>&lt;p&gt;Reactive programing is hot stuff at the moment and the
&lt;a href=&#34;https://www.coursera.org/course/reactive&#34;&gt;Coursera Principles of Reactive Programming&lt;/a&gt;
course has &lt;strong&gt;just&lt;/strong&gt; started (its not too late to enroll).&lt;/p&gt;

&lt;p&gt;Recently, I&amp;rsquo;ve been hearing good things about &lt;a href=&#34;https://github.com/Netflix/RxJava&#34;&gt;RxJava&lt;/a&gt; (
a port of .Net&amp;rsquo;s &lt;a href=&#34;http://msdn.microsoft.com/en-gb/data/gg577609.aspx&#34;&gt;Reactive extensions&lt;/a&gt;
) so I wanted to learn some more. Then I stumbled upon a video from a recent
&lt;a href=&#34;http://www.meetup.com/SF-Scala/&#34;&gt;SF Scala&lt;/a&gt; meetup
which covered what it is and how they implemented the core and then added
support for other JVM languages.&lt;/p&gt;

&lt;p&gt;Two things immediately struck me:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Observables are not opnionated about how the backend works.  It could be
concurrent or swapped out with a thread pool, an actor
or an nio event &amp;amp; event loop&amp;hellip; Pretty cool, this means there is a single way
of handling the code no matter if the backend is synchronus or asynchronus.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;The methods for manipulating multiple observers, chaining or nesting
is extremely powerful, yet easy to understand.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;I&amp;rsquo;m really looking forward to using it, to me its an easier abstraction to
understand for handling streams of data and seemly less complex than using Plays
excellent &lt;code&gt;Iteratee.Concurrent&lt;/code&gt; library.&lt;/p&gt;

&lt;p&gt;Enjoy:&lt;/p&gt;

&lt;p&gt;&lt;div class=&#34;embed video-player&#34;&gt;
&lt;iframe class=&#34;youtube-player&#34; type=&#34;text/html&#34;
    width=&#34;640&#34; height=&#34;385&#34;
    src=&#34;http://www.youtube.com/embed/tOMK_FYJREw&#34;
    allowfullscreen frameborder=&#34;0&#34;&gt;
&lt;/iframe&gt;
&lt;/div&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Typesafe&#39;s Activator</title>
      <link>http://rosslawley.co.uk/typesafe-activator/</link>
      <pubDate>Tue, 24 Sep 2013 00:00:00 +0000</pubDate>
      
      <guid>http://rosslawley.co.uk/typesafe-activator/</guid>
      <description>

&lt;p&gt;Yesterday the &lt;a href=&#34;http://typesafe.com/blog/announcing-activator-10-create-reactive-apps-in-minutes&#34;&gt;Typesafe Activator&lt;/a&gt;
hit 1.0. If you haven&amp;rsquo;t heard about it and use scala or the jvm then take five
minutes and check it out - its worth it.&lt;/p&gt;

&lt;h1 id=&#34;what-is-it:8f899c775a0faeb02adf96bdfce96cff&#34;&gt;What is it?&lt;/h1&gt;

&lt;p&gt;My recommendation alone not enough and you what to know more about it before
installing it?  No problems, let me convince you.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Typesafe Activator is a local web &amp;amp; command-line tool that helps developers
get started with the Typesafe Platform.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Whats that give you?  Basically, a real nice UI in the browser for creating web
applications from templates.  The &lt;a href=&#34;http://typesafe.com/activator/templates&#34;&gt;templates&lt;/a&gt;
cover &amp;ldquo;hello world&amp;rdquo; in scala to using &lt;a href=&#34;http://akka.io&#34;&gt;Akka&lt;/a&gt;, &lt;a href=&#34;http://playframework.com&#34;&gt;
Play&lt;/a&gt; and &lt;a href=&#34;http://www.scala-lang.org/&#34;&gt;Scala&lt;/a&gt; to create
modern scalable reactive web sites.&lt;/p&gt;

&lt;p&gt;Its quick and easy to get going - I chose the
&lt;a href=&#34;http://typesafe.com/activator/template/play-mongo-knockout&#34;&gt;Play Reactive Mongo and knockout.js&lt;/a&gt;
template&lt;/p&gt;

&lt;p class=&#34;text-center&#34;&gt;
&lt;img src=&#34;http://rosslawley.co.uk/images/activator-loading.png&#34;&gt;
&lt;/p&gt;

&lt;p&gt;In the background it downloads all the resources you need to create the project
from the template.  Starting a new project is extremely simple and once the
project is loaded you get to use the Web UI in anger.&lt;/p&gt;

&lt;p class=&#34;text-center&#34;&gt;
&lt;img src=&#34;http://rosslawley.co.uk/images/activator-orientation.png&#34;&gt;
&lt;/p&gt;

&lt;h1 id=&#34;the-tutorial:8f899c775a0faeb02adf96bdfce96cff&#34;&gt;The tutorial&lt;/h1&gt;

&lt;p&gt;Once loaded, you get the tutorial for this template:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;The world is going reactive&lt;/p&gt;

&lt;p&gt;Not long ago, response times in the seconds were considered appropriate. Browser
refreshes were the norm in web applications. Systems would go down for hours of
maintenance, or even be rebooted nightly, and this was ok because people only
expected the systems to be up during business hours..&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;em&gt;Exciting stuff!&lt;/em&gt;  So not only can you code, compile and test your application
all in the browser - there&amp;rsquo;s a tutorial to guide you through the various new
concepts as well.&lt;/p&gt;

&lt;p&gt;The reactive mongo tutorial, gets you up and running using creating a reactive
Play web application with a rich front end and scalable backend.  It uses
&lt;a href=&#34;http://reactivemongo.org&#34;&gt;Reactive Mongo&lt;/a&gt; an asynchronous non blocking scala
mongodb driver for the database.  The play framework for the webserver,
&lt;a href=&#34;http://coffeescript.org&#34;&gt;coffeescript&lt;/a&gt; and &lt;a href=&#34;http://knockoutjs.com&#34;&gt;knockout.js&lt;/a&gt;
for the frontend.&lt;/p&gt;

&lt;p&gt;The tutorial walks you through how the various parts of the app work together and
links through to the code.  Next it sets tasks to update parts of the app, extending
it and adding functionality.&lt;/p&gt;

&lt;p&gt;This quickly, gets you up to speed, so if you are interested in any of the
Typesafe stack then download activator now and you&amp;rsquo;ll be up and running in minutes!&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>